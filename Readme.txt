  
Projet Machine Learning ‚Äì Analyse et Pr√©diction Client√®le Bancaire  
---------------------------------------------------------------
Auteurs : NGNATCHEU THIERRY & NGUEKOUO CINTHIA 

üëã Bienvenue !

Ce projet a √©t√© r√©alis√© dans le cadre d‚Äôun travail en Machine Learning appliqu√© √† un dataset bancaire. Le but : utiliser les donn√©es de clients pour comprendre leurs comportements et pr√©dire deux choses essentielles pour une banque :

1. Est-ce qu‚Äôun client va accepter un pr√™t personnel ? (classification)
2. Quel est le revenu estim√© d‚Äôun client ? (r√©gression)

L‚Äôapproche est compl√®te : nettoyage des donn√©es, traitement des valeurs manquantes, exploration visuelle, mod√©lisation avec plusieurs algorithmes, √©valuation des performances... et en bonus : une simulation en live avec le public √† la fin.

---

 Ce qu'on a dans le jeu de donn√©es

- Source : https://www.kaggle.com/code/bmag8923/alllife-bank-loan-predictions?select=Bank_Personal_Loan_Modelling.csv
- Fichier utilis√© : Financial_Datasets.csv

Le jeu de donn√©es contient des infos classiques sur les clients : √¢ge, niveau d'√©ducation, revenu, utilisation de carte de cr√©dit, pr√™t immobilier, etc.
 
Voici un aper√ßu rapide :

- Age / Experience : √¢ge et ann√©es d'exp√©rience
- Income : revenu annuel
- Family : taille du foyer
- Education : niveau d‚Äô√©tude (1 = Undergraduate √† 3 = Graduate)
- CCAvg : d√©penses mensuelles avec carte de cr√©dit
- Mortgage, CD Account, Online, etc.

Certaines valeurs manquantes ont √©t√© intentionnellement ajout√©es pour tester le pipeline de nettoyage. On les a trait√©es de deux mani√®res :
- Par imputation m√©diane pour les cas simples
- Par mod√®le de r√©gression quand une meilleure pr√©diction √©tait possible (ex. : pr√©dire l'exp√©rience √† partir de l'√¢ge)

---

 Standardisation & Visualisation

Les variables num√©riques comme le revenu ou l'√¢ge ont √©t√© standardis√©es pour √©viter que certaines dominent les autres lors de l'entra√Ænement des mod√®les. On a compar√© les donn√©es avant et apr√®s pour v√©rifier que la transformation √©tait bien faite (graphiques inclus).

---

 Mod√®les utilis√©s

Pour chaque t√¢che classification et r√©gression, on a test√© 4 mod√®les diff√©rents :
-  Deux mod√®les ensemblistes (Random Forest, Gradient Boosting, Stacking, Bagging)
-  Un mod√®le appris en cours (Naive Bayes, R√©gression lin√©aire)
-  Un mod√®le plus original (SVR, KNN.)
---

 M√©triques utilis√©es :

- Pour la classification : accuracy, recall, AUC, precision
- Pour la r√©gression : R¬≤, RMSE, MAE

---

 
Structure du projet :
- classification.ipynb : Notebook pour la t√¢che de classification
- regression.ipynb : Notebook pour la t√¢che de r√©gression
- environment.yml : Fichier pour cr√©er l'environnement jupyter
- README.txt : Ce fichier de documentation


